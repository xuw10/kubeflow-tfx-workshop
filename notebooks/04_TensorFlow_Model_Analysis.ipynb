{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuSYVbwEYNHw"
   },
   "source": [
    "# TensorFlow Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPt5BHTwy_0F"
   },
   "source": [
    "\n",
    "\n",
    "This notebook illustrates how TensorFlow Model Analysis (TFMA) can be used to investigate and visualize the characteristics of a dataset and the performance of a model.  We'll use a model that we trained previously, and now you get to play with the results!\n",
    "\n",
    "The model we trained was for the [Chicago Taxi Example](https://github.com/tensorflow/model-analysis/tree/master/examples/chicago_taxi), which uses the [Taxi Trips dataset](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew) released by the City of Chicago.\n",
    "\n",
    "Note: This site provides applications using data that has been modified for use from its original source, www.cityofchicago.org, the official website of the City of Chicago. The City of Chicago makes no claims as to the content, accuracy, timeliness, or completeness of any of the data provided at this site. The data provided at this site is subject to change at any time. It is understood that the data provided at this site is being used at oneâ€™s own risk.\n",
    "\n",
    "[Read more](https://cloud.google.com/bigquery/public-data/chicago-taxi) about the dataset in [Google BigQuery](https://cloud.google.com/bigquery/). Explore the full dataset in the [BigQuery UI](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips).\n",
    "\n",
    "Key Point: As a modeler and developer, think about how this data is used and the potential benefits and harm a model's predictions can cause. A model like this could reinforce societal biases and disparities. Is a feature relevant to the problem you want to solve or will it introduce bias? For more information, read about <a target='_blank' href='https://developers.google.com/machine-learning/fairness-overview/'>ML fairness</a>.\n",
    "\n",
    "Key Point: In order to understand `TFMA` and how it works with Apache Beam, you'll need to know a little bit about Apache Beam itself.  The <a target='_blank' href='https://beam.apache.org/documentation/programming-guide/'>Beam Programming Guide</a> is a great place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_model_analysis==0.13.1 in /opt/conda/lib/python3.6/site-packages (0.13.1)\n",
      "Requirement already satisfied: jupyter<2,>=1 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.16.2)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (7.4.2)\n",
      "Requirement already satisfied: six<2,>=1.9 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.12.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.11 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-transform<1,>=0.13 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: scipy==1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.1.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.7 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (3.7.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.7.8)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.4.1)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (4.4.3)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.1.0)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (6.0.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (7.4.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (3.4.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.3.2)\n",
      "Requirement already satisfied: dill<0.2.10,>=0.2.9 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.2.9)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.0.0)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.12.0)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.9.0)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.0.0)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.5.4)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.7)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.17.1)\n",
      "Requirement already satisfied: pydot<1.3,>=1.2.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.2.4)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.13)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.21.24)\n",
      "Requirement already satisfied: pyarrow<0.14.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.8 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.19.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2018.9)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.1.0)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.5.28)\n",
      "Requirement already satisfied: google-cloud-core<0.30.0,>=0.28.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.29.1)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.7.4)\n",
      "Requirement already satisfied: google-cloud-pubsub<0.40.0,>=0.39.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.39.1)\n",
      "Requirement already satisfied: google-cloud-bigtable<0.33.0,>=0.31.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.32.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.6.1)\n",
      "Requirement already satisfied: absl-py<2,>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-metadata<0.14,>=0.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf<4,>=3.7->tensorflow_model_analysis==0.13.1) (40.9.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.5.0)\n",
      "Requirement already satisfied: tornado<7,>=4.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.1.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.6.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.10)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.2.4)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (18.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.2.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.8.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.3.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.5.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from jupyter-console->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.0.9)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.6.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.13.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.1.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (3.0.1)\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.6/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (5.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.4.5)\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/conda/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.21.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.6/site-packages (from pydot<1.3,>=1.2.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.4.0)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.6/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.15)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-core<0.30.0,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.12dev,>=0.11.4 in /opt/conda/lib/python3.6/site-packages (from google-cloud-pubsub<0.40.0,>=0.39.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.11.4)\n",
      "Requirement already satisfied: google-resumable-media>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.6/site-packages (from tensorflow-metadata<0.14,>=0.12.1->tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (1.5.9)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.1->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client>=5.2.0->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.8.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (19.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.0.4)\n",
      "Requirement already satisfied: monotonic>=0.1 in /opt/conda/lib/python3.6/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.5)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-core<0.30.0,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.6.3)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_model_analysis==0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "/opt/conda/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n",
      "Installing /opt/conda/lib/python3.6/site-packages/tensorflow_model_analysis/static -> tfma_widget_js\n",
      "Symlinking: /usr/local/share/jupyter/nbextensions/tfma_widget_js -> /opt/conda/lib/python3.6/site-packages/tensorflow_model_analysis/static\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/jupyter-nbextension\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/jupyter_core/application.py\", line 266, in launch_instance\n",
      "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/notebook/nbextensions.py\", line 988, in start\n",
      "    super(NBExtensionApp, self).start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/jupyter_core/application.py\", line 255, in start\n",
      "    self.subapp.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/notebook/nbextensions.py\", line 716, in start\n",
      "    self.install_extensions()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/notebook/nbextensions.py\", line 695, in install_extensions\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/notebook/nbextensions.py\", line 225, in install_nbextension_python\n",
      "    destination=dest, logger=logger\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/notebook/nbextensions.py\", line 184, in install_nbextension\n",
      "    os.symlink(path, full_dest)\n",
      "FileExistsError: [Errno 17] File exists: '/opt/conda/lib/python3.6/site-packages/tensorflow_model_analysis/static' -> '/usr/local/share/jupyter/nbextensions/tfma_widget_js'\n",
      "/opt/conda/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n",
      "Enabling notebook extension tfma_widget_js/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter nbextension install --py --symlink tensorflow_model_analysis\n",
    "jupyter nbextension enable --py tensorflow_model_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP!\n",
    "\n",
    "# YOU MUST STOP ALL KERNELS!!\n",
    "\n",
    "# THEN RESTART YOUR KERNEL!!!\n",
    "\n",
    "# THEN RE-RUN THIS NOTEBOOK!!!!\n",
    "AND IGNORE THE WARNINGS ^^ ABOVE ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fnm6Mj3vTGLm"
   },
   "source": [
    "The columns in the dataset are:\n",
    "<table>\n",
    "<tr><td>pickup_community_area</td><td>fare</td><td>trip_start_month</td></tr>\n",
    "\n",
    "<tr><td>trip_start_hour</td><td>trip_start_day</td><td>trip_start_timestamp</td></tr>\n",
    "<tr><td>pickup_latitude</td><td>pickup_longitude</td><td>dropoff_latitude</td></tr>\n",
    "<tr><td>dropoff_longitude</td><td>trip_miles</td><td>pickup_census_tract</td></tr>\n",
    "<tr><td>dropoff_census_tract</td><td>payment_type</td><td>company</td></tr>\n",
    "<tr><td>trip_seconds</td><td>dropoff_community_area</td><td>tips</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZj-impiAD_l"
   },
   "source": [
    "## Install TensorFlow Model Analysis (TFMA)\n",
    "\n",
    "This will pull in all the dependencies, and will take a minute.  Please ignore the warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SA2E343NAMRF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_model_analysis==0.13.1 in /opt/conda/lib/python3.6/site-packages (0.13.1)\n",
      "Requirement already satisfied: jupyter<2,>=1 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.16.2)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (7.4.2)\n",
      "Requirement already satisfied: scipy==1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.1.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.11 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-transform<1,>=0.13 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: six<2,>=1.9 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (1.12.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.7 in /opt/conda/lib/python3.6/site-packages (from tensorflow_model_analysis==0.13.1) (3.7.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.7.8)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (4.4.3)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (3.4.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (7.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.3.2)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.9.0)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.12.0)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.21.24)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2018.9)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.7)\n",
      "Requirement already satisfied: dill<0.2.10,>=0.2.9 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.2.9)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.0.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.17.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.5.4)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.0.0)\n",
      "Requirement already satisfied: pydot<1.3,>=1.2.0 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.2.4)\n",
      "Requirement already satisfied: grpcio<2,>=1.8 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.19.0)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.13)\n",
      "Requirement already satisfied: pyarrow<0.14.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: google-cloud-bigtable<0.33.0,>=0.31.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.32.2)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.1.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<0.40.0,>=0.39.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.39.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.6.1)\n",
      "Requirement already satisfied: google-cloud-core<0.30.0,>=0.28.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.29.1)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.7.4)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /opt/conda/lib/python3.6/site-packages (from apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.5.28)\n",
      "Requirement already satisfied: tensorflow-metadata<0.14,>=0.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (0.13.0)\n",
      "Requirement already satisfied: absl-py<2,>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf<4,>=3.7->tensorflow_model_analysis==0.13.1) (40.9.0)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.2.4)\n",
      "Requirement already satisfied: tornado<7,>=4.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.10)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (18.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.6.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.8.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from qtconsole->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.3.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from jupyter-console->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.0.9)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.3)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (3.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (3.0.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.13.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (4.6.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.6/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (5.1.3)\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/conda/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.21.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (4.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.6/site-packages (from pydot<1.3,>=1.2.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.4.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.12dev,>=0.11.4 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigtable<0.33.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.11.4)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigtable<0.33.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.9.0)\n",
      "Requirement already satisfied: google-resumable-media>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.3.2)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.6/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (0.15)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.6/site-packages (from tensorflow-metadata<0.14,>=0.12.1->tensorflow-transform<1,>=0.13->tensorflow_model_analysis==0.13.1) (1.5.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client>=5.2.0->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (1.1.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.1->notebook->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.1.7)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow_model_analysis==0.13.1) (0.5.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (19.1.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7->tensorflow_model_analysis==0.13.1) (0.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (2.8)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-bigtable<0.33.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.6.3)\n",
      "Requirement already satisfied: monotonic>=0.1 in /opt/conda/lib/python3.6/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.11->tensorflow_model_analysis==0.13.1) (1.5)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFMA version: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "\n",
    "# Install TFMA\n",
    "# This will pull in all the dependencies, and will take a minute\n",
    "# Please ignore the warnings\n",
    "!pip install tensorflow_model_analysis==0.13.1\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('TFMA version: {}'.format(tfma.version.VERSION_STRING))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RptgLn2RYuK3"
   },
   "source": [
    "## Load The Files\n",
    "We'll download a zip file that has everything we need.  That includes:\n",
    "\n",
    "* Training and evaluation datasets\n",
    "* Data schema\n",
    "* Training results as EvalSavedModels\n",
    "\n",
    "Note: We are downloading with HTTPS from a Google Cloud server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4QXVIM7iglN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what we downloaded:\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0:\n",
      "total 24\n",
      "drwxr-xr-x 4 root root 4096 Jun 13 21:38 data\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 run_0\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 run_1\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 run_2\n",
      "-rw-r--r-- 1 root root 4441 Jun 13 21:38 schema.pbtxt\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/data:\n",
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 Jun 13 21:38 eval\n",
      "drwxr-xr-x 2 root root 4096 Jun 13 21:38 train\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/data/eval:\n",
      "total 628\n",
      "-rw-r--r-- 1 root root 641080 Jun 13 21:38 data.csv\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/data/train:\n",
      "total 1252\n",
      "-rw-r--r-- 1 root root 1281866 Jun 13 21:38 data.csv\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_0:\n",
      "total 4\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 eval_model_dir\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_0/eval_model_dir:\n",
      "total 4\n",
      "drwxr-xr-x 4 root root 4096 Jun 13 21:38 1544225322\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_0/eval_model_dir/1544225322:\n",
      "total 692\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 assets\n",
      "-rw-r--r-- 1 root root 698559 Jun 13 21:38 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 variables\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_0/eval_model_dir/1544225322/assets:\n",
      "total 8\n",
      "-rw-r--r-- 1 root root 1138 Jun 13 21:38 vocab_compute_and_apply_vocabulary_1_vocabulary\n",
      "-rw-r--r-- 1 root root   49 Jun 13 21:38 vocab_compute_and_apply_vocabulary_vocabulary\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_0/eval_model_dir/1544225322/variables:\n",
      "total 68\n",
      "-rw-r--r-- 1 root root     8 Jun 13 21:38 variables.data-00000-of-00002\n",
      "-rw-r--r-- 1 root root 58828 Jun 13 21:38 variables.data-00001-of-00002\n",
      "-rw-r--r-- 1 root root   995 Jun 13 21:38 variables.index\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_1:\n",
      "total 4\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 eval_model_dir\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_1/eval_model_dir:\n",
      "total 4\n",
      "drwxr-xr-x 4 root root 4096 Jun 13 21:38 1544225718\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_1/eval_model_dir/1544225718:\n",
      "total 692\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 assets\n",
      "-rw-r--r-- 1 root root 698559 Jun 13 21:38 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 variables\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_1/eval_model_dir/1544225718/assets:\n",
      "total 8\n",
      "-rw-r--r-- 1 root root 1138 Jun 13 21:38 vocab_compute_and_apply_vocabulary_1_vocabulary\n",
      "-rw-r--r-- 1 root root   49 Jun 13 21:38 vocab_compute_and_apply_vocabulary_vocabulary\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_1/eval_model_dir/1544225718/variables:\n",
      "total 68\n",
      "-rw-r--r-- 1 root root     8 Jun 13 21:38 variables.data-00000-of-00002\n",
      "-rw-r--r-- 1 root root 58828 Jun 13 21:38 variables.data-00001-of-00002\n",
      "-rw-r--r-- 1 root root   995 Jun 13 21:38 variables.index\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_2:\n",
      "total 4\n",
      "drwxr-xr-x 3 root root 4096 Jun 13 21:38 eval_model_dir\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_2/eval_model_dir:\n",
      "total 4\n",
      "drwxr-xr-x 4 root root 4096 Jun 13 21:38 1544225766\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_2/eval_model_dir/1544225766:\n",
      "total 692\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 assets\n",
      "-rw-r--r-- 1 root root 698559 Jun 13 21:38 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 Jun 13 21:38 variables\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_2/eval_model_dir/1544225766/assets:\n",
      "total 8\n",
      "-rw-r--r-- 1 root root 1138 Jun 13 21:38 vocab_compute_and_apply_vocabulary_1_vocabulary\n",
      "-rw-r--r-- 1 root root   49 Jun 13 21:38 vocab_compute_and_apply_vocabulary_vocabulary\n",
      "\n",
      "/var/tmp/tmp1rn1lbk3/eval_saved_models-0.11.0/run_2/eval_model_dir/1544225766/variables:\n",
      "total 68\n",
      "-rw-r--r-- 1 root root     8 Jun 13 21:38 variables.data-00000-of-00002\n",
      "-rw-r--r-- 1 root root 58828 Jun 13 21:38 variables.data-00001-of-00002\n",
      "-rw-r--r-- 1 root root   995 Jun 13 21:38 variables.index\n"
     ]
    }
   ],
   "source": [
    "# Download the zip file from GCP and unzip it\n",
    "import tempfile, requests, zipfile, io\n",
    "BASE_DIR = tempfile.mkdtemp()\n",
    "TFMA_DIR = os.path.join(BASE_DIR, 'eval_saved_models-0.11.0')\n",
    "DATA_DIR = os.path.join(TFMA_DIR, 'data')\n",
    "OUTPUT_DIR = os.path.join(TFMA_DIR, 'output')\n",
    "SCHEMA = os.path.join(TFMA_DIR, 'schema.pbtxt')\n",
    "\n",
    "response = requests.get('https://storage.googleapis.com/tfx-colab-datasets/eval_saved_models-0.11.0.zip', stream=True)\n",
    "zipfile.ZipFile(io.BytesIO(response.content)).extractall(BASE_DIR)\n",
    "\n",
    "print(\"Here's what we downloaded:\")\n",
    "!ls -lR {TFMA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xa7ZDV1MycO"
   },
   "source": [
    "## Parse the Schema\n",
    "\n",
    "Among the things we downloaded was a schema for our data that was created by [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/).  Let's parse that now so that we can use it with TFMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uW5eB4TPcwFw"
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "from tensorflow.core.example import example_pb2\n",
    "from tensorflow import python_io\n",
    "\n",
    "schema = schema_pb2.Schema()\n",
    "contents = file_io.read_file_to_string(SCHEMA)\n",
    "schema = text_format.Parse(contents, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UP3yuJxfNXRL"
   },
   "source": [
    "## Use the Schema to Create TFRecords\n",
    "\n",
    "We need to give TFMA access to our dataset, so let's create a TFRecords file.  We can use our schema to create it, since it gives us the correct type for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-wud3fPczl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 2630788 Jun 13 21:38 /var/tmp/tmp1rn1lbk3/train_data.rio\r\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "datafile = os.path.join(DATA_DIR, 'eval', 'data.csv')\n",
    "reader = csv.DictReader(open(datafile, 'r'))\n",
    "examples = []\n",
    "for line in reader:\n",
    "  example = example_pb2.Example()\n",
    "  for feature in schema.feature:\n",
    "    key = feature.name\n",
    "    if len(line[key]) > 0:\n",
    "      if feature.type == schema_pb2.FLOAT:\n",
    "        example.features.feature[key].float_list.value[:] = [float(line[key])]\n",
    "      elif feature.type == schema_pb2.INT:\n",
    "        example.features.feature[key].int64_list.value[:] = [int(line[key])]\n",
    "      elif feature.type == schema_pb2.BYTES:\n",
    "        example.features.feature[key].bytes_list.value[:] = [line[key].encode('utf8')]\n",
    "    else:\n",
    "      if feature.type == schema_pb2.FLOAT:\n",
    "        example.features.feature[key].float_list.value[:] = []\n",
    "      elif feature.type == schema_pb2.INT:\n",
    "        example.features.feature[key].int64_list.value[:] = []\n",
    "      elif feature.type == schema_pb2.BYTES:\n",
    "        example.features.feature[key].bytes_list.value[:] = []\n",
    "  examples.append(example)\n",
    "\n",
    "TFRecord_file = os.path.join(BASE_DIR, 'train_data.rio')\n",
    "with python_io.TFRecordWriter(TFRecord_file) as writer:\n",
    "  for example in examples:\n",
    "    writer.write(example.SerializeToString())\n",
    "  writer.flush()\n",
    "  writer.close()\n",
    "\n",
    "!ls -l {TFRecord_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm5luW1EN7g7"
   },
   "source": [
    "## Run TFMA and Render Metrics\n",
    "\n",
    "Now we're ready to create a function that we'll use to run TFMA and render metrics.  It requires an [`EvalSavedModel`](https://www.tensorflow.org/api_docs/python/tf/saved_model), a list of [`SliceSpecs`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SingleSliceSpec), and an index into the SliceSpec list.  It will create an EvalResult using [`tfma.run_model_analysis`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/run_model_analysis), and use it to create a `SlicingMetricsViewer` using [`tfma.view.render_slicing_metrics`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_slicing_metrics), which will render a visualization of our dataset using the slice we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2wANNF_2dCR"
   },
   "outputs": [],
   "source": [
    "def run_and_render(eval_model=None, slice_list=None, slice_idx=0):\n",
    "  \"\"\"Runs the model analysis and renders the slicing metrics\n",
    "\n",
    "  Args:\n",
    "      eval_model: An instance of tf.saved_model saved with evaluation data\n",
    "      slice_list: A list of tfma.slicer.SingleSliceSpec giving the slices\n",
    "      slice_idx: An integer index into slice_list specifying the slice to use\n",
    "\n",
    "  Returns:\n",
    "      A SlicingMetricsViewer object if in Jupyter notebook; None if in Colab.\n",
    "  \"\"\"\n",
    "  eval_result = tfma.run_model_analysis(eval_shared_model=eval_model,\n",
    "                                          data_location=TFRecord_file,\n",
    "                                          file_format='tfrecords',\n",
    "                                          slice_spec=slice_list,\n",
    "                                          output_path='sample_data',\n",
    "                                          extractors=None)\n",
    "  return tfma.view.render_slicing_metrics(eval_result, slicing_spec=slices[slice_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSl9qyTCbBKR"
   },
   "source": [
    "### Slicing and Dicing\n",
    "\n",
    "We previously trained a model, and now we've loaded the results.  Let's take a look at our visualizations, starting with using TFMA to slice along particular features.  But first we need to read in the EvalSavedModel from one of our previous training runs.\n",
    "\n",
    "* To define the slice you want to visualize you create a [`tfma.slicer.SingleSliceSpec`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SingleSliceSpec)\n",
    "\n",
    "* To use [`tfma.view.render_slicing_metrics`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_slicing_metrics) you can either use the name of the column (by setting `slicing_column`) or provide a [`tfma.slicer.SingleSliceSpec`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SingleSliceSpec) (by setting `slicing_spec`)\n",
    "* If neither is provided, the overview will be displayed\n",
    "\n",
    "Plots are interactive:\n",
    "\n",
    "* Click and drag to pan\n",
    "* Scroll to zoom\n",
    "* Right click to reset the view\n",
    "\n",
    "Simply hover over the desired data point to see more details.  Select from four different types of plots using the selections at the bottom.\n",
    "\n",
    "For example, we'll be setting `slicing_column` to look at the `trip_start_hour` feature in our `SliceSpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJ5_UMnWYmaE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow_model_analysis/slicer/slicer.py:407: BeamDeprecationWarning: RemoveDuplicates is deprecated since 2.12. Use Distinct instead.\n",
      "  | 'IncrementCounter' >> beam.Map(increment_counter))\n",
      "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940da7704a384940920b1b4d3557469c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TFMA results for the first training run\n",
    "# This will take a minute\n",
    "eval_model_base_dir_0 = os.path.join(TFMA_DIR, 'run_0', 'eval_model_dir')\n",
    "eval_model_dir_0 = os.path.join(eval_model_base_dir_0, next(os.walk(eval_model_base_dir_0))[1][0])\n",
    "eval_shared_model_0 = tfma.default_eval_shared_model(eval_saved_model_path=eval_model_dir_0)\n",
    "\n",
    "# Slice our data by the trip_start_hour feature\n",
    "slices = [tfma.slicer.SingleSliceSpec(columns=['trip_start_hour'])]\n",
    "\n",
    "run_and_render(eval_model=eval_shared_model_0, slice_list=slices, slice_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJuxvGCpn4yF"
   },
   "source": [
    "### Slices Overview\n",
    "\n",
    "The default visualization is the **Slices Overview** when the number of slices is small. It shows the values of metrics for each slice. Since we've selected `trip_start_hour` above, it's showing us metrics like accuracy and AUC for each hour, which allows us to look for issues that are specific to some hours and not others.\n",
    "\n",
    "In the visualization above:\n",
    "\n",
    "* Try sorting the feature column, which is our `trip_start_hours` feature, by clicking on the column header\n",
    "* Try sorting by precision, and **notice that the precision for some of the hours with examples is 0, which may indicate a problem**\n",
    "\n",
    "The chart also allows us to select and display different metrics in our slices.\n",
    "\n",
    "* Try selecting different metrics from the \"Show\" menu\n",
    "* Try selecting recall in the \"Show\" menu, and **notice that the recall for some of the hours with examples is 0, which may indicate a problem**\n",
    "\n",
    "It is also possible to set a threshold to filter out slices with smaller numbers of examples, or \"weights\".  You can type a minimum number of examples, or use the slider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQT-1Ckcnd_7"
   },
   "source": [
    "### Metrics Histogram\n",
    "\n",
    "This view also supports a **Metrics Histogram** as an alternative visualization, which is also the default view when the number of slices is large. The results will be divided into buckets and the number of slices / total weights / both can be visualized. Columns can be sorted by clicking on the column header.  Slices with small weights can be filtered out by setting the threshold. Further filtering can be applied by dragging the grey band. To reset the range, double click the band. Filtering can also be used to remove outliers in the visualization and the metrics tables. Click the gear icon to switch to a logarithmic scale instead of a linear scale.\n",
    "\n",
    "* Try selecting \"Metrics Histogram\" in the Visualization menu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSnqI6Esb1XM"
   },
   "source": [
    "### More Slices\n",
    "\n",
    "Let's create a whole list of `SliceSpec`s, which will allow us to select any of the slices in the list.  We'll select the `trip_start_day` slice (days of the week) by setting the `slice_idx` to `1`.  **Try changing the `slice_idx` to `0` or `2` and running again to examine different slices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "355wqvY3yBod"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c16430187411ea56f366be1dfc5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slices = [tfma.slicer.SingleSliceSpec(columns=['trip_start_hour']),\n",
    "          tfma.slicer.SingleSliceSpec(columns=['trip_start_day']),\n",
    "          tfma.slicer.SingleSliceSpec(columns=['trip_start_month'])]\n",
    "run_and_render(eval_model=eval_shared_model_0, slice_list=slices, slice_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsXM0NYGeajg"
   },
   "source": [
    "You can create feature crosses to analyze combinations of features.  Let's create a `SliceSpec` to look at a cross of `trip_start_day` and `trip_start_hour`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7vbFS1Me1SH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605898fe2369402f9e40783c4ce2c6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slices = [tfma.slicer.SingleSliceSpec(columns=['trip_start_day', 'trip_start_hour'])]\n",
    "run_and_render(eval_shared_model_0, slices, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmeODqrUfJw2"
   },
   "source": [
    "Crossing the two columns creates a lot of combinations!  Let's narrow down our cross to only look at **trips that start at noon**.  Then let's select `accuracy` from the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdvBNfcHfRWg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ebdcddbd9443788f1aa259148b7370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slices = [tfma.slicer.SingleSliceSpec(columns=['trip_start_day'], features=[('trip_start_hour', 12)])]\n",
    "run_and_render(eval_shared_model_0, slices, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kK7TO2dRkEDZ"
   },
   "source": [
    "That's interesting, we only seem to have trips starting at noon on **Sundays, Mondays, and Fridays**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meRvFkKcPbux"
   },
   "source": [
    "## Tracking Model Performance Over Time\n",
    "\n",
    "Your training dataset will be used for training your model, and will hopefully be representative of your test dataset and the data that will be sent to your model in production.  However, while the data in inference requests may remain the same as your training data, in many cases it will start to change enough so that the performance of your model will change.\n",
    "\n",
    "That means that you need to monitor and measure your model's performance on an ongoing basis, so that you can be aware of and react to changes.  Let's take a look at how TFMA can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vm2y2DqNF4HL"
   },
   "source": [
    "### Measure Performance For New Data\n",
    "We downloaded the results of three different training runs above, so let's load them now and use TFMA to see how they compare using [`render_time_series`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_time_series).  We can specify particular slices to look at.  Let's compare our training runs for trips that started at noon.\n",
    "\n",
    "* Select a metric from the dropdown to add the time series graph for that metric\n",
    "* Close unwanted graphs\n",
    "* Hover over data points (the ends of line segments in the graph) to get more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJYUOjmFfuPy"
   },
   "outputs": [],
   "source": [
    "def get_eval_result(base_dir, output_dir, data_loc, slice_spec):\n",
    "  eval_model_dir = os.path.join(base_dir, next(os.walk(base_dir))[1][0])\n",
    "  eval_shared_model = tfma.default_eval_shared_model(eval_saved_model_path=eval_model_dir)\n",
    "\n",
    "  return tfma.run_model_analysis(eval_shared_model=eval_shared_model,\n",
    "                                          data_location=data_loc,\n",
    "                                          file_format='tfrecords',\n",
    "                                          slice_spec=slice_spec,\n",
    "                                          output_path=output_dir,\n",
    "                                          extractors=None)\n",
    "\n",
    "slices = [tfma.slicer.SingleSliceSpec()]\n",
    "output_dir_0 = os.path.join(TFMA_DIR, 'output', 'run_0')\n",
    "result_ts0 = get_eval_result(os.path.join(TFMA_DIR, 'run_0', 'eval_model_dir'),\n",
    "                             output_dir_0, TFRecord_file, slices)\n",
    "output_dir_1 = os.path.join(TFMA_DIR, 'output', 'run_1')\n",
    "result_ts1 = get_eval_result(os.path.join(TFMA_DIR, 'run_1', 'eval_model_dir'),\n",
    "                             output_dir_1, TFRecord_file, slices)\n",
    "output_dir_2 = os.path.join(TFMA_DIR, 'output', 'run_2')\n",
    "result_ts2 = get_eval_result(os.path.join(TFMA_DIR, 'run_2', 'eval_model_dir'),\n",
    "                             output_dir_2, TFRecord_file, slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsO-gqCRK0ar"
   },
   "source": [
    "### How does it look today?\n",
    "First, we'll imagine that we've trained and deployed our model yesterday, and now we want to see how it's doing on the new data coming in today.  The visualization will start by displaying accuracy.  Add AUC and average loss by using the \"Add metric series\" menu.\n",
    "\n",
    "Note: In the metric series charts the X axis is the model ID number of the model run that you're examining.  The numbers themselves are not meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjEws8T0cDm9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfab6536afe4d8eb1d97de4f695f4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TimeSeriesViewer(config={'isModelCentric': True}, data=[{'metrics': {'auc': {'doubleValue': 0.9466296434402466â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results_from_disk = tfma.load_eval_results([output_dir_0, output_dir_1],\n",
    "                                                tfma.constants.MODEL_CENTRIC_MODE)\n",
    "\n",
    "tfma.view.render_time_series(eval_results_from_disk, slices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQ7kZxESN9Bx"
   },
   "source": [
    "Now we'll imagine that another day has passed and we want to see how it's doing on the new data coming in today, compared to the previous two days. Again add AUC and average loss by using the \"Add metric series\" menu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjQmlXMmLwHf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73de645fad534858b129ba81498455c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TimeSeriesViewer(config={'isModelCentric': True}, data=[{'metrics': {'post_export_metrics/example_count': {'doâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results_from_disk = tfma.load_eval_results([output_dir_0, output_dir_1, output_dir_2],\n",
    "                                                tfma.constants.MODEL_CENTRIC_MODE)\n",
    "\n",
    "tfma.view.render_time_series(eval_results_from_disk, slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tghWegsjhpkt"
   ],
   "name": "chicago_taxi.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
